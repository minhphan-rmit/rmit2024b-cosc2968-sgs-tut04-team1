{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000; text-align: center;\">\n",
    "\n",
    "<span style=\"color: red;\">\n",
    "\n",
    "# **RMIT Vietnam**\n",
    "\n",
    "</span>\n",
    "\n",
    "**School of Science and Technology**\n",
    "\n",
    "### **Foundations of Artificial Intelligence for STEM**\n",
    "\n",
    "<br><br><br><br><br><br><br> \n",
    "\n",
    "## **Assignment 3 - OPTION A (PROGRAMMING): Machine Learning**\n",
    "\n",
    "<div style=\"line-height: 1.6; color: #000;\">\n",
    "\n",
    "**Teacher**: Dr. Nhat-Quang Tran (Lecturer), Ms. Anh Van Le (Tutorial Lecturer)  \n",
    "**Student Name**: Tran Thanh Lam, Phan Nhat Minh, Tran Tu Tam, Nguyen Ngoc Thien Ngan, Ha Loc   \n",
    "**Student ID**: s4038329  \n",
    "**Tutorial Group**: Friday 8:30  Tut04_VanAnh_Team01  \n",
    "**Submission Due Date**: Aug 14, 2024 by 17:00\n",
    "\n",
    "</div>\n",
    "<br><br><br><br><br><br><br> \n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #000; text-align: center;\">\n",
    "\n",
    "# **Background and Design**\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Describe the Requirements of the Project and Its Purpose**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1 Requirements of the Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Project Overview`\n",
    "\n",
    "This project is designed to give students practical experience with nearly the entire machine learning pipeline. You will collaborate in groups to identify a suitable dataset, perform data exploration and preprocessing, train models, and evaluate the results.\n",
    "\n",
    "#### `Dataset Criteria`\n",
    "You have the freedom to choose any dataset, provided it adheres to the following criteria:\n",
    "\n",
    "- **Task:** Regression\n",
    "- **Features:** At least 5 features, including a minimum of one categorical and four numerical features.\n",
    "- **Samples:** At least 1,000 samples\n",
    "- The dataset can be sourced from the internet or manually collected (e.g., via web scraping).\n",
    "\n",
    "#### `Required Steps`\n",
    "\n",
    "Your project must include the following key steps:\n",
    "\n",
    "1. **Data Exploration:**\n",
    "   - Load the dataset into your Jupyter Notebook.\n",
    "   - Use descriptive statistics, visualizations, and correlation analysis to explore the dataset.\n",
    "   - Understand the data distribution, relationships among features, and identify potential issues (e.g., outliers, missing values).\n",
    "\n",
    "2. **Data Preprocessing:**\n",
    "   - Address missing values using appropriate techniques (e.g., imputation or deletion).\n",
    "   - Detect and manage outliers.\n",
    "   - If necessary, encode categorical features using suitable methods (e.g., one-hot encoding).\n",
    "   - Split the dataset into training and testing sets.\n",
    "\n",
    "3. **Model Training and Evaluation:**\n",
    "   - Train at least four models, including at least two that differ from those covered in lectures.\n",
    "   - Evaluate the models using appropriate metrics (e.g., R² score, RMSE, MAE) and K-fold cross-validation.\n",
    "   - Compare the models' performance and justify your selection of the best model.\n",
    "\n",
    "4. **Hyperparameter Tuning:**\n",
    "   - Use random search to optimize the hyperparameters of your best-performing model.\n",
    "   - Justify the choice of hyperparameters to tune and their value ranges.\n",
    "\n",
    "5. **Model Testing and Analysis:**\n",
    "   - Test your best model on the test set.\n",
    "   - Analyze the model's performance and derive insights.\n",
    "   - Discuss any limitations and suggest possible improvements.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 Purpose of the Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### `Project Purpose`\n",
    "\n",
    "##### This project aims to:\n",
    "\n",
    "1. **Practical Application of Machine Learning:**  \n",
    "   - Provide students with hands-on experience in the key stages of the machine learning pipeline, including dataset selection, data exploration, preprocessing, model training, and evaluation.\n",
    "\n",
    "2. **Team Collaboration:**  \n",
    "   - Encourage collaboration among students as they work in groups to solve real-world data challenges, enhancing their ability to work effectively in a team environment.\n",
    "\n",
    "3. **Critical Thinking and Problem-Solving:**  \n",
    "   - Develop students' critical thinking skills by requiring them to analyze data, identify potential issues, and make informed decisions to improve model performance.\n",
    "\n",
    "4. **Skill Development:**  \n",
    "   - Equip students with the necessary skills to apply machine learning techniques to regression tasks, including model selection, hyperparameter tuning, and performance evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Clarifying the Choice of Topic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Explain why we choosing this topic`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `What is Coral Bleaching?`\n",
    "\n",
    "Corals are living animals that coexist with tiny algae called zooxanthellae in a symbiotic relationship. These algae provide corals with food and oxygen, while the corals offer them a secure habitat. However, when corals face stressful conditions—such as elevated temperatures, pollution, or changes in water chemistry—they expel the zooxanthellae. This loss causes the corals to turn white, a phenomenon known as \"bleaching.\" Corals can't survive long in this bleached state, but there's hope: if the stress is alleviated in time, the zooxanthellae can return, allowing the corals to recover.\n",
    "\n",
    "#### `Why Should We Care?`\n",
    "\n",
    "Caring about coral bleaching is crucial because coral reefs are vital to the health of our oceans and our planet. They provide habitat and food for countless marine species, protect coastlines from erosion and storms, and play a key role in regulating the Earth's climate by absorbing and storing carbon dioxide. The decline of coral reefs affects entire ecosystems and the communities that rely on them. Additionally, coral reefs are irreplaceable natural wonders, rich in biodiversity and beauty. Protecting them from bleaching ensures that future generations can continue to marvel at these incredible ecosystems.\n",
    "#### `What Can You Do to Help?`\n",
    "\n",
    "#### Importance of Understanding Coral Bleaching\n",
    "1. **Prediction and Mitigation:**  \n",
    "   - Sea surface temperature anomalies (SSTA) and thermal stress anomalies (TSA) are key indicators for predicting and mitigating the impacts of future bleaching events (Spalding, Ravilious, & Green, 2001).\n",
    "\n",
    "2. **Early Warning Systems:**  \n",
    "   - Studying these factors enables researchers to develop early warning systems that can alert stakeholders to impending bleaching events.\n",
    "\n",
    "3. **Conservation Strategies:**  \n",
    "   - Insights from this research help shape effective conservation strategies aimed at protecting coral reefs.\n",
    "\n",
    "4. **Reducing Human-Induced Stressors:**  \n",
    "   - By understanding these environmental conditions, efforts can be guided to reduce anthropogenic stressors that further endanger coral reefs (Brown, 1997).\n",
    "\n",
    "Tackling coral bleaching is crucial not only for preserving biodiversity but also for maintaining the resilience and sustainability of marine ecosystems and the economies that depend on them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Explain how we choosing the dataset topic`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this analysis was obtained from the Biological and Chemical Oceanography Data Management Office (BCO-DMO) website. The data has been utilized for educational and personal research purposes only. We express our gratitude to the BCO-DMO and the respective contributors for making this valuable resource available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"color: #000; text-align: center;\">\n",
    "\n",
    "# **Data Exploration**\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"border-left: 5px solid green; padding-left: 10px;\">Purpose of Imported Libraries and Modules</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`pandas`**: Provides data structures and data analysis tools for handling and manipulating tabular data.\n",
    "- **`numpy`**: Facilitates numerical operations and array manipulations.\n",
    "- **`matplotlib.pyplot`**: Offers functions for creating and customizing plots.\n",
    "- **`sklearn.base.BaseEstimator`**: Provides a base class for all scikit-learn estimators, allowing for custom estimators.\n",
    "- **`sklearn.base.TransformerMixin`**: Provides a mixin class for transformers, enabling custom transformations of data.\n",
    "- **`sklearn.pipeline.FeatureUnion`**: Allows for combining multiple feature extraction methods into a single feature union.\n",
    "- **`sklearn.pipeline.Pipeline`**: Facilitates the creation of machine learning pipelines by chaining together multiple steps.\n",
    "- **`sklearn.preprocessing.StandardScaler`**: Standardizes features by removing the mean and scaling to unit variance.\n",
    "- **`sklearn.impute.SimpleImputer`**: Handles missing values by imputing them with a specified strategy.\n",
    "- **`sklearn.preprocessing.OneHotEncoder`**: Converts categorical features into a one-hot encoded format.\n",
    "- **`sklearn.model_selection.KFold`**: Provides k-fold cross-validation for evaluating model performance.\n",
    "- **`statistics.mean`**: Computes the arithmetic mean of a list of numbers.\n",
    "- **`joblib`**: Provides utilities for saving and loading Python objects, particularly for machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  \n",
    "from sklearn.preprocessing import OneHotEncoder      \n",
    "from sklearn.model_selection import KFold   \n",
    "from statistics import mean\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"border-left: 5px solid green; padding-left: 10px;\">Load the Dataset</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(r'.\\dataset\\global_bleaching_environmental.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"border-left: 5px solid green; padding-left: 10px;\">Essential Features for Exploratory Data</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Selected Features for EDA`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Because the dataset contains a large number of features, we have selected the following essential ones for exploratory data analysis (EDA) to ensure a focused and effective analysis:\n",
    "- **Latitude_Degrees**: To understand the geographical distribution.\n",
    "- **Longitude_Degrees**: To understand the geographical distribution.\n",
    "- **Ocean_Name**: To explore differences across different oceans.\n",
    "- **Realm_Name**: To examine variations across different realms.\n",
    "- **Ecoregion_Name**: To assess differences across various ecoregions.\n",
    "- **Country_Name**: For analyzing geographic and political influences.\n",
    "- **State_Island_Province_Name**: For more detailed regional analysis.\n",
    "- **Distance_to_Shore**: To study the relationship between proximity to shore and coral bleaching.\n",
    "- **Exposure**: To assess how exposure affects bleaching.\n",
    "- **Turbidity**: To analyze the effect of water clarity on coral health.\n",
    "- **Cyclone_Frequency**: To evaluate the impact of cyclone frequency on coral bleaching.\n",
    "- **Depth_m**: To study the influence of depth on coral bleaching.\n",
    "- **Percent_Cover**: To analyze the extent of coral cover.\n",
    "- **Bleaching_Level**: For understanding the severity of bleaching.\n",
    "- **Percent_Bleaching**: To quantify the extent of bleaching.\n",
    "- **Temperature_Mean**: To explore the impact of average temperature on bleaching.\n",
    "- **Temperature_Maximum**: To study the effect of maximum temperature on bleaching.\n",
    "- **Temperature_Kelvin**: For understanding temperature in absolute terms.\n",
    "- **Windspeed**: To investigate the role of wind speed in bleaching.\n",
    "- **SSTA_Mean**: To analyze sea surface temperature anomalies on average.\n",
    "- **SSTA_Maximum**: To study the impact of extreme sea surface temperature anomalies.\n",
    "- **SSTA_DHW**: To explore the relationship between degree heating weeks and bleaching.\n",
    "\n",
    "\n",
    "These features have been chosen because they provide crucial insights into the environmental conditions and stress factors affecting coral bleaching, while excluding less relevant or empty fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is Python code for remain the feature that neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of necessary features\n",
    "necessary_features = [\n",
    "    'Latitude_Degrees',\n",
    "    'Longitude_Degrees',\n",
    "    'Ocean_Name',\n",
    "    'Realm_Name',\n",
    "    'Ecoregion_Name',\n",
    "    'Country_Name',\n",
    "    'State_Island_Province_Name',\n",
    "    'Distance_to_Shore',\n",
    "    'Exposure',\n",
    "    'Turbidity',\n",
    "    'Cyclone_Frequency',\n",
    "    'Depth_m',\n",
    "    'Percent_Cover',\n",
    "    'Bleaching_Level',\n",
    "    'Percent_Bleaching',\n",
    "    'Temperature_Mean',\n",
    "    'Temperature_Maximum',\n",
    "    'Temperature_Kelvin',\n",
    "    'Windspeed',\n",
    "    'SSTA_Mean',\n",
    "    'SSTA_Maximum',\n",
    "    'SSTA_DHW'\n",
    "]\n",
    "\n",
    "# Drop columns that are not in the necessary_features list\n",
    "df_filtered = raw_data[necessary_features]\n",
    "\n",
    "# Optionally, save the filtered DataFrame to a new CSV file\n",
    "df_filtered.to_csv('./dataset/global_bleaching_environmental_filtered.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"border-left: 5px solid green; padding-left: 10px;\">Explore the dataset</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude_Degrees</th>\n",
       "      <th>Longitude_Degrees</th>\n",
       "      <th>Cyclone_Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41361.000000</td>\n",
       "      <td>41361.000000</td>\n",
       "      <td>41361.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.558085</td>\n",
       "      <td>34.966127</td>\n",
       "      <td>52.159650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.732185</td>\n",
       "      <td>103.404598</td>\n",
       "      <td>7.589593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-30.262500</td>\n",
       "      <td>-179.974300</td>\n",
       "      <td>18.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.902500</td>\n",
       "      <td>-78.385600</td>\n",
       "      <td>47.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.776100</td>\n",
       "      <td>96.843300</td>\n",
       "      <td>50.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.050500</td>\n",
       "      <td>120.880400</td>\n",
       "      <td>55.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.750000</td>\n",
       "      <td>179.964500</td>\n",
       "      <td>105.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Latitude_Degrees  Longitude_Degrees  Cyclone_Frequency\n",
       "count      41361.000000       41361.000000       41361.000000\n",
       "mean           7.558085          34.966127          52.159650\n",
       "std           15.732185         103.404598           7.589593\n",
       "min          -30.262500        -179.974300          18.310000\n",
       "25%           -4.902500         -78.385600          47.940000\n",
       "50%           10.776100          96.843300          50.920000\n",
       "75%           20.050500         120.880400          55.730000\n",
       "max           36.750000         179.964500         105.800000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
